{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7cb4f29b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "f2eb57be"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('C:/Users/Brendan/Downloads/compas-scores-two-years.csv')\n",
    "df = pd.read_csv('compas-scores-two-years.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0df45b8d"
   },
   "outputs": [],
   "source": [
    "#data wrangling \n",
    "df['race'] = df['race'].replace('African-American', 1).replace('Caucasian', 0)\n",
    "\n",
    "df = df[(df['race'] == 0) | (df['race'] == 1)]\n",
    "\n",
    "df['sex'] = df['sex'].replace('Male', 1).replace('Female', 0)\n",
    "\n",
    "df['score_text'] = df['score_text'].replace('High', 1).replace('Medium', 0).replace('Low', -1)\n",
    "\n",
    "df['c_charge_degree'] = df['c_charge_degree'].replace('M',1).replace('F',0)\n",
    "\n",
    "df['days_in_jail'] = (pd.to_datetime(df['c_jail_out'])-pd.to_datetime(df['c_jail_in'])).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I4_aEA1TKhl6",
    "outputId": "95c47c57-1f0c-4e4a-a03b-75dff88ecf25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                            0\n",
       "name                          0\n",
       "first                         0\n",
       "last                          0\n",
       "compas_screening_date         0\n",
       "sex                           0\n",
       "dob                           0\n",
       "age                           0\n",
       "age_cat                       0\n",
       "race                          0\n",
       "juv_fel_count                 0\n",
       "decile_score                  0\n",
       "juv_misd_count                0\n",
       "juv_other_count               0\n",
       "priors_count                  0\n",
       "days_b_screening_arrest     235\n",
       "c_jail_in                   235\n",
       "c_jail_out                  235\n",
       "c_case_number                14\n",
       "c_offense_date              999\n",
       "c_arrest_date              5165\n",
       "c_days_from_compas           14\n",
       "c_charge_degree               0\n",
       "c_charge_desc                21\n",
       "is_recid                      0\n",
       "r_case_number              3089\n",
       "r_charge_degree            3089\n",
       "r_days_from_arrest         4087\n",
       "r_offense_date             3089\n",
       "r_charge_desc              3141\n",
       "r_jail_in                  4087\n",
       "r_jail_out                 4087\n",
       "violent_recid              6150\n",
       "is_violent_recid              0\n",
       "vr_case_number             5433\n",
       "vr_charge_degree           5433\n",
       "vr_offense_date            5433\n",
       "vr_charge_desc             5433\n",
       "type_of_assessment            0\n",
       "decile_score.1                0\n",
       "score_text                    0\n",
       "screening_date                0\n",
       "v_type_of_assessment          0\n",
       "v_decile_score                0\n",
       "v_score_text                  0\n",
       "v_screening_date              0\n",
       "in_custody                  180\n",
       "out_custody                 180\n",
       "priors_count.1                0\n",
       "start                         0\n",
       "end                           0\n",
       "event                         0\n",
       "two_year_recid                0\n",
       "days_in_jail                235\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identifying columns with a significant amount of NA values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mXE2F7Tf7zro",
    "outputId": "ac9291b7-e6ee-4dec-9b03-0a778e5d5efe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in data: 5915\n"
     ]
    }
   ],
   "source": [
    "# from pandas.io.formats.info import DataFrameTableBuilderVerbose\n",
    "# dropping rows with NA values as the optimizer doesn't work with them\n",
    "df = df[['race','age', 'c_charge_degree', 'score_text', 'sex', 'priors_count', 'days_b_screening_arrest', 'decile_score', 'is_recid','two_year_recid']].dropna()\n",
    "\n",
    "X = df[['race','age', 'c_charge_degree', 'score_text', 'sex', 'priors_count', 'days_b_screening_arrest', 'decile_score', 'is_recid']]\n",
    "z = df['race']\n",
    "y = df['two_year_recid']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, z_train, z_test, y_train, y_test = train_test_split(X, z, y, test_size=0.25, random_state=5243)\n",
    "print(\"Rows in data:\",len(df))\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P2ikf6ieZZhQ",
    "outputId": "4a60314f-0e11-471d-ff96-f90f3daa2bb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54314416 0.77434024 0.04912813 0.38513112 0.94981787 0.49186705\n",
      " 0.21205341 0.32446764 0.13078458]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-81aaad0ba03e>:16: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1 + np.exp(np.matmul(X, -theta)))\n",
      "<ipython-input-10-81aaad0ba03e>:19: RuntimeWarning: divide by zero encountered in log\n",
      "  return -sum(np.log(p(theta,X)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3.89885881e-06,  4.61017542e-06, -3.76204843e-06,  1.17037838e-05,\n",
       "        7.28905183e-06, -4.86598610e-06,  7.01936574e-07, -1.59452851e-05,\n",
       "       -8.32805157e-06])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = np.random.rand(X_train_normalized.shape[1])\n",
    "print(theta)\n",
    "\n",
    "import scipy\n",
    "from scipy.optimize import minimize\n",
    "from numpy.core.fromnumeric import transpose\n",
    "# from numpy import linalg as LA\n",
    "\n",
    "def condition_1(theta, X, Z, c):\n",
    "  return -np.matmul((Z-Z.mean()),np.matmul(theta,transpose(X)))/X.shape[0] + c\n",
    "\n",
    "def condition_2(theta, X, Z, c):\n",
    "  return np.matmul((Z-Z.mean()),np.matmul(theta,transpose(X)))/X.shape[0] + c\n",
    "\n",
    "def p(theta,X):\n",
    "  return 1/(1 + np.exp(np.matmul(X, -theta)))\n",
    "\n",
    "def minimizer(theta,X):\n",
    "  return -sum(np.log(p(theta,X)))\n",
    "\n",
    "optimization = scipy.optimize.minimize(\n",
    "    minimizer,\n",
    "    args=X_train_normalized,\n",
    "    x0=theta,\n",
    "    method='SLSQP',\n",
    "    constraints=(\n",
    "        {'type': 'ineq', 'fun': condition_1, 'args': (X_train_normalized, z_train , 0.8)},\n",
    "        {'type': 'ineq', 'fun': condition_2, 'args': (X_train_normalized, z_train , 0.8)}),\n",
    "        options={\"maxiter\": 100000})\n",
    "theta = optimization.x\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing results\n",
    "X_test_r0 = scaler.fit_transform(X_test)[X_test.reset_index()[X_test.reset_index()['race']==0].index]\n",
    "X_test_r1 = scaler.fit_transform(X_test)[X_test.reset_index()[X_test.reset_index()['race']==1].index]\n",
    "y_test_r0 = y_test.iloc[X_test.reset_index()[X_test.reset_index()['race']==0].index]\n",
    "y_test_r1 = y_test.iloc[X_test.reset_index()[X_test.reset_index()['race']==1].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.8073022312373225\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "preds = 1/(1+np.exp(np.matmul(X_test_normalized, theta)))\n",
    "print(\"Overall accuracy:\",((preds > 0.5) == y_test).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Caucasian: 0.7970049916805324\n",
      "Accuracy for African-American 0.8143507972665148\n"
     ]
    }
   ],
   "source": [
    "# Calibration\n",
    "preds_r0 = 1/(1+np.exp(np.matmul(X_test_r0, theta)))\n",
    "preds_r1 = 1/(1+np.exp(np.matmul(X_test_r1, theta)))\n",
    "print(\"Accuracy for Caucasian:\",((preds_r0 > 0.5) == y_test_r0).mean())\n",
    "print(\"Accuracy for African-American\",((preds_r1 > 0.5) == y_test_r1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of predicting two_year_recid = 1 for Caucasian: 0.5041597337770383\n",
      "Probability of predicting two_year_recid = 1 for African-American: 0.5466970387243736\n"
     ]
    }
   ],
   "source": [
    "# Parity\n",
    "print(\"Probability of predicting two_year_recid = 1 for Caucasian:\",((preds_r0 > 0.5) == 1).mean())\n",
    "print(\"Probability of predicting two_year_recid = 1 for African-American:\",((preds_r1 > 0.5) == 1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Caucasian when true y = 0: 0.7558139534883721\n",
      "Accuracy for African-American when true y = 0: 0.8005115089514067\n",
      "Accuracy for Caucasian when true y = 1: 0.8521400778210116\n",
      "Accuracy for African-American when true y = 1: 0.8254620123203286\n"
     ]
    }
   ],
   "source": [
    "# Odds\n",
    "test_results = pd.DataFrame({\"X\":(1/(1+np.exp(np.matmul(X_test_normalized, theta)))>0.5),\"z\":z_test,\"y\":y_test})\n",
    "rs0 = test_results[test_results['y']==0]\n",
    "print(\"Accuracy for Caucasian when true y = 0:\",(rs0[rs0['z']==0]['X'] == 0).mean())\n",
    "print(\"Accuracy for African-American when true y = 0:\",(rs0[rs0['z']==1]['X'] == 0).mean())\n",
    "\n",
    "rs1 = test_results[test_results['y']==1]\n",
    "print(\"Accuracy for Caucasian when true y = 1:\",(rs1[rs1['z']==0]['X']).mean())\n",
    "print(\"Accuracy for African-American when true y = 1:\",(rs1[rs1['z']==1]['X']).mean())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
